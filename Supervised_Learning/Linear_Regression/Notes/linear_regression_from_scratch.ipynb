{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import math\n",
        "import random\n",
        "from collections import Counter\n",
        "import re"
      ],
      "metadata": {
        "id": "_fAEKMxQv6rQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "VIcKh5NBvnXU",
        "outputId": "aa5e4777-3fbe-402a-f8df-0306f68526f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-72facbb5-d8ca-4018-9797-588e2e83418e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-72facbb5-d8ca-4018-9797-588e2e83418e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving carmax_cleaned.csv to carmax_cleaned.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = list(uploaded.keys())[0]\n",
        "raw = pd.read_csv(filename)"
      ],
      "metadata": {
        "id": "tNXrkmaWv5Xi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "camry = raw[(raw[\"makeName\"] == \"Toyota\") & (raw[\"modelName\"] == \"Camry\")].copy()\n",
        "camry = camry[camry[\"price\"].notna() & (camry[\"price\"] > 0)]\n",
        "camry = camry[camry[\"unitMileage/value\"].notna()]"
      ],
      "metadata": {
        "id": "jKBWtrMmwGhN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "camry.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvag_3-3wcAQ",
        "outputId": "09f1f425-0715-4581-acaf-6ff4af54178f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 777 entries, 10 to 5345\n",
            "Columns: 166 entries, accidentCount to vin\n",
            "dtypes: float64(25), int64(13), object(128)\n",
            "memory usage: 1013.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "camry[\"age\"] = 2025 - camry[\"carYear\"]\n",
        "camry[\"mileage\"] = camry[\"unitMileage/value\"]"
      ],
      "metadata": {
        "id": "J4tT3f9DweJW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"distance\" in camry.columns and camry[\"distance\"].notna().any():\n",
        "    camry[\"listing_distance_miles\"] = pd.to_numeric(camry[\"distance\"], errors=\"coerce\")\n",
        "else:\n",
        "    camry[\"listing_distance_miles\"] = float(\"nan\")"
      ],
      "metadata": {
        "id": "lb66JbA40PFf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trim-related flags\n",
        "camry[\"trimName\"] = camry[\"trimName\"].fillna(\"Unknown\")\n",
        "camry[\"le_flag\"] = camry[\"trimName\"].str.contains(r\"\\bLE\\b\", na=False).astype(int)\n",
        "camry[\"hybrid_flag\"] = camry[\"trimName\"].str.contains(\"Hybrid\", na=False).astype(int)\n",
        "\n",
        "# Exterior color (top 10 + Other)\n",
        "K_COLOR = 10\n",
        "if \"exteriorColorName\" in camry.columns:\n",
        "    top_colors = camry[\"exteriorColorName\"].fillna(\"Unknown\").value_counts().nlargest(K_COLOR).index.tolist()\n",
        "    camry[\"exteriorColorCat\"] = camry[\"exteriorColorName\"].where(camry[\"exteriorColorName\"].isin(top_colors), other=\"Other\")\n",
        "else:\n",
        "    camry[\"exteriorColorCat\"] = \"Unknown\"\n",
        "\n",
        "# Trim (top 10 + Other)\n",
        "K_TRIM = 10\n",
        "top_trims = camry[\"trimName\"].value_counts().nlargest(K_TRIM).index.tolist()\n",
        "camry[\"trimCat\"] = camry[\"trimName\"].where(camry[\"trimName\"].isin(top_trims), other=\"Other\")\n",
        "\n",
        "# Options (options/0..9) -> pick top 15 frequent options as binary flags\n",
        "option_cols = [c for c in camry.columns if re.fullmatch(r\"options/\\d+\", c)]\n",
        "def norm_opt(s: str) -> str:\n",
        "    s = s.strip().lower()\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    return s\n",
        "\n",
        "all_opts = []\n",
        "for c in option_cols:\n",
        "    all_opts += camry[c].dropna().astype(str).tolist()\n",
        "normed_opts = [norm_opt(s) for s in all_opts if isinstance(s, str)]\n",
        "opt_counts = Counter(normed_opts)\n",
        "M_OPTS = 15\n",
        "top_opts = [opt for opt, _ in opt_counts.most_common(M_OPTS)]\n",
        "\n",
        "for opt in top_opts:\n",
        "    col_name = f\"opt_{re.sub(r'[^a-z0-9]+','_', opt)}\"\n",
        "    def has_opt_row(row):\n",
        "        for c in option_cols:\n",
        "            val = row.get(c)\n",
        "            if pd.isna(val):\n",
        "                continue\n",
        "            if norm_opt(str(val)) == opt:\n",
        "                return 1\n",
        "        return 0\n",
        "    camry[col_name] = camry.apply(has_opt_row, axis=1)\n",
        "\n",
        "# One-hot encodings for color & trim\n",
        "color_dummies = pd.get_dummies(camry[\"exteriorColorCat\"], prefix=\"color\")\n",
        "trim_dummies  = pd.get_dummies(camry[\"trimCat\"], prefix=\"trim\")\n",
        "\n",
        "# Assemble features\n",
        "numeric_cols = [\"age\", \"mileage\", \"listing_distance_miles\"]\n",
        "binary_cols  = [\"le_flag\", \"hybrid_flag\"] + [c for c in camry.columns if c.startswith(\"opt_\")]\n",
        "\n",
        "X_df = pd.concat([\n",
        "    camry[numeric_cols],\n",
        "    camry[binary_cols],\n",
        "    color_dummies,\n",
        "    trim_dummies\n",
        "], axis=1)\n",
        "\n",
        "y_df = camry[\"price\"].copy()\n",
        "\n",
        "# Clean numeric cols: drop all-NaN numeric columns, fill others w/ median\n",
        "numeric_cols_clean = []\n",
        "for c in numeric_cols:\n",
        "    if c in X_df.columns:\n",
        "        X_df[c] = pd.to_numeric(X_df[c], errors=\"coerce\")\n",
        "        if X_df[c].isna().all():\n",
        "            X_df.drop(columns=[c], inplace=True)\n",
        "        else:\n",
        "            X_df[c] = X_df[c].fillna(X_df[c].median())\n",
        "            numeric_cols_clean.append(c)\n",
        "\n",
        "# Scale numeric features (z-score) â€” helps gradient descent\n",
        "scaler_stats = {}\n",
        "for c in numeric_cols_clean:\n",
        "    mu = X_df[c].mean()\n",
        "    sd = X_df[c].std(ddof=0)\n",
        "    if sd == 0 or pd.isna(sd):\n",
        "        sd = 1.0\n",
        "    scaler_stats[c] = {\"mean\": float(mu), \"std\": float(sd)}\n",
        "    X_df[c] = (X_df[c] - mu) / sd\n",
        "\n",
        "feature_cols = list(X_df.columns)\n",
        "\n"
      ],
      "metadata": {
        "id": "_mhGH6GqyOHZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "0Uppz8HCkZZs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(\n",
        "    X_df, y_df, test_size=0.2, random_state=42, shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "HGUxMoPv2VLr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = X_train_df.columns.tolist()"
      ],
      "metadata": {
        "id": "rZI_7TWGkQw5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_matrix_and_vector(X_df, y_df):\n",
        "    X = [list(map(float, row)) for row in X_df.values.tolist()]\n",
        "    y = [float(v) for v in y_df.values.tolist()]\n",
        "    return X, y\n",
        "\n",
        "X_train, y_train = df_to_matrix_and_vector(X_train_df, y_train_df)\n",
        "X_test,  y_test  = df_to_matrix_and_vector(X_test_df,  y_test_df)\n"
      ],
      "metadata": {
        "id": "o5PUaFCqkeyM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = [0.0] * (len(feature_cols) + 1)\n",
        "beta[0] = float(y_train_df.mean())"
      ],
      "metadata": {
        "id": "PU7meVtjkpQF"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if \"intercept\" not in X_train_df.columns:\n",
        "    X_train_df.insert(0, \"intercept\", 1.0)\n",
        "if \"intercept\" not in X_test_df.columns:\n",
        "    X_test_df.insert(0, \"intercept\", 1.0)"
      ],
      "metadata": {
        "id": "MGn8q5FADguB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(X_train_df, beta, y_train_df):\n",
        "  m = X_train_df.shape[0]\n",
        "  n = len(beta)\n",
        "  total_sse = 0.0\n",
        "  for i in range(m):\n",
        "    row = X_train_df.iloc[i]\n",
        "    y_hat_i = 0.0\n",
        "    for j in range(n):\n",
        "      y_hat_i += beta[j] * float(row.iloc[j])\n",
        "\n",
        "    err = y_hat_i - float(y_train_df.iloc[i])\n",
        "    total_sse += err * err\n",
        "\n",
        "  total_sse = total_sse / (2.0 * m)\n",
        "  return total_sse"
      ],
      "metadata": {
        "id": "JY6il1WMDhdX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predictions(beta, X_df):\n",
        "    m = X_df.shape[0]\n",
        "    n = len(beta)\n",
        "    y_hats = []\n",
        "    for i in range(m):\n",
        "        row = X_df.iloc[i]\n",
        "        y_hat_i = 0.0\n",
        "        for j in range(n):\n",
        "            y_hat_i += beta[j] * float(row.iloc[j])\n",
        "        y_hats.append(y_hat_i)\n",
        "    return y_hats\n"
      ],
      "metadata": {
        "id": "M0kQxNOUho5M"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradients(X_df, y_df, beta):\n",
        "    m = X_df.shape[0]\n",
        "    n = len(beta)\n",
        "    y_hats = predictions(beta, X_df)  # reuse your helper\n",
        "\n",
        "    grads = [0.0] * n\n",
        "    for i in range(m):\n",
        "        err = y_hats[i] - float(y_df.iloc[i])\n",
        "        row = X_df.iloc[i]\n",
        "        for j in range(n):\n",
        "            grads[j] += err * float(row.iloc[j])\n",
        "\n",
        "    for j in range(n):\n",
        "        grads[j] /= m\n",
        "    return grads"
      ],
      "metadata": {
        "id": "BPkKRQbtl0k9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X_df, y_df, beta, lr=0.03, epochs=3000, verbose_every=500):\n",
        "    history = []\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        grads = compute_gradients(X_df, y_df, beta)\n",
        "        for j in range(len(beta)):\n",
        "            beta[j] -= lr * grads[j]\n",
        "        if verbose_every and (epoch % verbose_every == 0 or epoch == 1 or epoch == epochs):\n",
        "            history.append((epoch, loss(X_df, beta, y_df)))\n",
        "    return beta, history"
      ],
      "metadata": {
        "id": "kHt-4Xp8l6OT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_error_series(y_df, y_hat_list):\n",
        "    m = len(y_hat_list)\n",
        "    total = 0.0\n",
        "    for i in range(m):\n",
        "        d = y_hat_list[i] - float(y_df.iloc[i])\n",
        "        total += d * d\n",
        "    return total / m"
      ],
      "metadata": {
        "id": "r3CxLwYJl_ey"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta, history = gradient_descent(X_train_df, y_train_df, beta, lr=0.03, epochs=3000, verbose_every=500)"
      ],
      "metadata": {
        "id": "veRL_7BXmIEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_preds = predictions(beta, X_train_df)\n",
        "test_preds  = predictions(beta, X_test_df)\n",
        "\n",
        "train_mse = mean_squared_error_series(y_train_df, train_preds)\n",
        "test_mse  = mean_squared_error_series(y_test_df,  test_preds)\n",
        "\n",
        "print(f\"Train MSE: {train_mse:,.2f}\")\n",
        "print(f\" Test MSE: {test_mse:,.2f}\")\n",
        "print(\"History (first & last few):\", history[:3] + history[-3:])"
      ],
      "metadata": {
        "id": "LdcEj2CbmKH4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}